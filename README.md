# PPO-DEMO

A demo project for PPO algorithm.

## PPO Training
```shell script
python train.py
```

## PPO Inference
```shell script
python inference.py
```

## ðŸ“ºDemo
### Video
https://github.com/homzer/PPO-DEMO/assets/65876923/a374ebba-113c-45c9-ac0a-45abcf6ef155
